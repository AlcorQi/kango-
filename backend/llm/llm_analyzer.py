import json
import os
from openai import OpenAI

class LLMAnalyzer:
    def __init__(self):
        self.client = OpenAI(
            api_key="sk-1d620b7df9ea4c36b88b06598b3ad19d",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        self.model_name = "qwen-plus"
    
    def load_anomalies_data(self, data_dir='./data/'):
        """åŠ è½½å¼‚å¸¸æ•°æ®"""
        anomalies_file = os.path.join(data_dir, 'anomalies.ndjson')
        summary_file = os.path.join(data_dir, 'summary.json')
        
        anomalies = []
        summary = {}
        
        # è¯»å–å¼‚å¸¸è®°å½•
        if os.path.exists(anomalies_file):
            with open(anomalies_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        anomalies.append(json.loads(line.strip()))
        
        # è¯»å–æ‘˜è¦ä¿¡æ¯
        if os.path.exists(summary_file):
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary = json.load(f)
        
        return anomalies, summary
    
    def generate_analysis_prompt(self, anomalies, summary):
        """ç”Ÿæˆåˆ†ææç¤ºè¯"""
        # ç»Ÿè®¡å¼‚å¸¸ç±»å‹
        anomaly_stats = {}
        for anomaly in anomalies:
            anomaly_type = anomaly.get('type', 'unknown')
            severity = anomaly.get('severity', 'unknown')
            if anomaly_type not in anomaly_stats:
                anomaly_stats[anomaly_type] = {'total': 0, 'severities': {}}
            anomaly_stats[anomaly_type]['total'] += 1
            anomaly_stats[anomaly_type]['severities'][severity] = \
                anomaly_stats[anomaly_type]['severities'].get(severity, 0) + 1
        
        # æ„å»ºç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²
        stats_str = "å¼‚å¸¸ç»Ÿè®¡ä¿¡æ¯:\n"
        for anomaly_type, stats in anomaly_stats.items():
            stats_str += f"- {anomaly_type.upper()}: {stats['total']} æ¬¡\n"
            for severity, count in stats['severities'].items():
                stats_str += f"  * {severity}: {count} æ¬¡\n"
        
        # æ„å»ºè¯¦ç»†å¼‚å¸¸ä¿¡æ¯
        details_str = "è¯¦ç»†å¼‚å¸¸è®°å½•:\n"
        for i, anomaly in enumerate(anomalies[:10], 1):  # é™åˆ¶å‰10æ¡é¿å…è¿‡é•¿
            details_str += f"{i}. ç±»å‹: {anomaly.get('type', 'unknown')}, "
            details_str += f"ä¸¥é‡æ€§: {anomaly.get('severity', 'unknown')}, "
            details_str += f"æ—¶é—´: {anomaly.get('detected_at', 'unknown')}\n"
            details_str += f"   ä¿¡æ¯: {anomaly.get('message', '')[:100]}...\n"
        
        prompt = f"""
æ‚¨æ˜¯ä¸€åä¸“ä¸šçš„ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹æ“ä½œç³»ç»Ÿå¼‚å¸¸æ£€æµ‹æ•°æ®è¿›è¡Œåˆ†æï¼š

{stats_str}

{details_str}

æ‘˜è¦ä¿¡æ¯:
- æ€»å¼‚å¸¸æ•°: {summary.get('total_anomalies', 0)}
- æŒ‰ä¸¥é‡æ€§åˆ†å¸ƒ: {json.dumps(summary.get('by_severity', {}), ensure_ascii=False)}
- æœ€åæ£€æµ‹æ—¶é—´: {summary.get('last_detection', 'æœªçŸ¥')}

è¯·ä»ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢è¿›è¡Œä¸“ä¸šåˆ†æï¼š

1. å½“å‰æ“ä½œç³»ç»Ÿéšæ‚£åˆ†æï¼š
   - è¯†åˆ«ä¸»è¦çš„ç³»ç»Ÿé£é™©ç±»å‹
   - åˆ†æå„ç±»å¼‚å¸¸çš„ä¸¥é‡ç¨‹åº¦å’Œå½±å“èŒƒå›´
   - è¯„ä¼°ç³»ç»Ÿçš„æ•´ä½“å¥åº·çŠ¶æ€

2. é’ˆå¯¹æ€§å»ºè®®ï¼š
   - é’ˆå¯¹æ¯ç§å¼‚å¸¸ç±»å‹æä¾›å…·ä½“çš„è§£å†³å»ºè®®
   - æå‡ºç³»ç»Ÿä¼˜åŒ–å’Œé¢„é˜²æªæ–½
   - æ¨èå¿…è¦çš„ç›‘æ§å’Œå‘Šè­¦è®¾ç½®

3. æ€»ç»“ï¼š
   ç”¨ä¸€æ®µç®€æ´ä¸“ä¸šçš„è¯æ€»ç»“å½“å‰ç³»ç»ŸçŠ¶æ€å’Œä¸»è¦å»ºè®®ï¼Œçªå‡ºé‡ç‚¹ã€‚

è¯·ç¡®ä¿åˆ†æè¯­è¨€æ¸…æ™°ã€ä¸“ä¸šã€æœ‰é€»è¾‘ï¼Œé¢å‘æŠ€æœ¯ç®¡ç†äººå‘˜ã€‚
"""
        return prompt
    
    def analyze_system_anomalies(self, data_dir='./data'):
        """åˆ†æç³»ç»Ÿå¼‚å¸¸å¹¶ç”ŸæˆæŠ¥å‘Š"""
        try:
            # åŠ è½½æ•°æ®
            anomalies, summary = self.load_anomalies_data(data_dir)
            
            if not anomalies:
                return "æœªå‘ç°å¼‚å¸¸æ•°æ®ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚"
            
            # ç”Ÿæˆæç¤ºè¯
            prompt = self.generate_analysis_prompt(anomalies, summary)
            
            # è°ƒç”¨å¤§æ¨¡å‹
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ“ä½œç³»ç»Ÿå¼‚å¸¸å’Œæä¾›ä¼˜åŒ–å»ºè®®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3  # é™ä½éšæœºæ€§ï¼Œä¿è¯ä¸“ä¸šæ€§å’Œä¸€è‡´æ€§
            )
            
            result = response.choices[0].message.content.strip()
            return result
            
        except Exception as e:
            return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def save_analysis_report(self, output_file, analysis_result):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        try:
            directory = os.path.dirname(os.path.abspath(output_file))
            if directory and not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("æ“ä½œç³»ç»Ÿå¼‚å¸¸æ™ºèƒ½åˆ†ææŠ¥å‘Š\n")
                f.write("åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸“ä¸šåˆ†æ\n")
                f.write("=" * 60 + "\n\n")
                f.write(analysis_result)
            
            print(f"ğŸ“Š LLMåˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {os.path.abspath(output_file)}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜LLMåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return False