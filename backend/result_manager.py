import json
import hashlib
import socket
import os
from datetime import datetime

class ResultManager:
    def __init__(self):
        self.results = []
        self.start_time = None
    
    def start_timer(self):
        """å¼€å§‹è®¡æ—¶"""
        import time
        self.start_time = time.time()
    
    def get_elapsed_time(self):
        """è·å–ç»è¿‡çš„æ—¶é—´"""
        import time
        if self.start_time:
            return time.time() - self.start_time
        return 0
    
    def add_result(self, result):
        """æ·»åŠ æ£€æµ‹ç»“æœ"""
        self.results.append(result)
        self.handle_detection(result)
    
    def handle_detection(self, result):
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        # æ ¹æ®ä¸¥é‡çº§åˆ«é€‰æ‹©è¡¨æƒ…ç¬¦å·
        severity_emoji = {
            'critical': 'ğŸ”¥',
            'high': 'ğŸš¨',
            'medium': 'âš ï¸',
            'low': 'â„¹ï¸'
        }.get(result.get('severity', 'medium'), 'ğŸ“')
        
        # æˆªæ–­è¿‡é•¿çš„æ¶ˆæ¯
        message_preview = result['message'][:100] + '...' if len(result['message']) > 100 else result['message']
        print(f"{severity_emoji} [{result['type'].upper()}] {message_preview}")
        
        # æŒä¹…åŒ–å­˜å‚¨
        try:
            self.persist_event(result)
        except Exception as e:
            print(f"âŒ æ•°æ®å†™å…¥å¤±è´¥: {e}")
    
    def persist_event(self, result):
        """æŒä¹…åŒ–å­˜å‚¨äº‹ä»¶"""
        data_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data'))
        os.makedirs(data_dir, exist_ok=True)
        anomalies = os.path.join(data_dir, 'anomalies.ndjson')
        summary_file = os.path.join(data_dir, 'summary.json')

        detected_at = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')
        source_file = result.get('file', '')
        line_number = result.get('line_number', 0)
        host_id = socket.gethostname()
        msg = result.get('message', '')
        raw_id = f"{host_id}{source_file}{line_number}{detected_at}{msg}".encode('utf-8')
        eid = hashlib.sha256(raw_id).hexdigest()[:16]
        sev_map = {"critical": "critical", "high": "major", "medium": "minor", "low": "minor"}
        sev = sev_map.get(result.get('severity', 'medium'), 'minor')
        
        event = {
            "schema_version": "1.0",
            "id": eid,
            "type": result.get('type'),
            "severity": sev,
            "message": msg,
            "source_file": source_file,
            "line_number": line_number,
            "detected_at": detected_at,
            "host_id": host_id,
            "processed": False
        }
        
        # å†™å…¥ä¸»å¼‚å¸¸æ–‡ä»¶
        with open(anomalies, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event) + "\n")
        
        # æŒ‰æ—¥æœŸå­˜å‚¨
        day_dir = os.path.join(data_dir, 'anomalies')
        os.makedirs(day_dir, exist_ok=True)
        day_file = os.path.join(day_dir, datetime.utcnow().strftime('%Y-%m-%d') + '.ndjson')
        with open(day_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event) + "\n")
        
        # æ›´æ–°æ‘˜è¦æ–‡ä»¶
        self.update_summary(summary_file, event, detected_at, sev)
    
    def update_summary(self, summary_file, event, detected_at, severity):
        """æ›´æ–°æ‘˜è¦æ–‡ä»¶"""
        if os.path.exists(summary_file):
            with open(summary_file, 'r', encoding='utf-8') as f:
                s = json.load(f)
        else:
            s = {
                "schema_version": "1.0",
                "date": datetime.utcnow().strftime('%Y-%m-%d'),
                "total_anomalies": 0,
                "by_severity": {"critical": 0, "major": 0, "minor": 0},
                "by_type": {},
                "hosts": [],
                "trend": []
            }
        
        s['total_anomalies'] = int(s.get('total_anomalies', 0)) + 1
        bs = s.get('by_severity', {"critical": 0, "major": 0, "minor": 0})
        bs[severity] = int(bs.get(severity, 0)) + 1
        s['by_severity'] = bs
        bt = s.get('by_type', {})
        t = event['type']
        bt[t] = int(bt.get(t, 0)) + 1
        s['by_type'] = bt
        s['last_detection'] = detected_at
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(s, f)
    
    def get_statistics(self, detector_names):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for detector_type in detector_names:
            count = len([r for r in self.results if r['type'] == detector_type])
            stats[detector_type] = count
        return stats
    
    def show_statistics(self, detector_names):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“ˆ æ£€æµ‹ç»Ÿè®¡:")
        print("-" * 50)
        
        stats = self.get_statistics(detector_names)
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸
        if not any(stats.values()):
            print("   æœªæ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸äº‹ä»¶")
            return
        
        # æŒ‰æ£€æµ‹æ•°é‡é™åºæ’åˆ—æ˜¾ç¤º
        for name, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
            status = "âœ…" if count > 0 else "âŒ"
            print(f"   {status} {name.upper():<12}: {count} æ¬¡")