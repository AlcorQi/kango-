import os
import sys
import time
import yaml
import argparse
from datetime import datetime
import gzip
import subprocess
import shutil
import platform

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ‰€æœ‰æ£€æµ‹å™¨
from src.detectors.oom_detector import OOMDetector
from src.detectors.panic_detector import PanicDetector
from src.detectors.reboot_detector import RebootDetector
from src.detectors.oops_detector import OopsDetector
from src.detectors.deadlock_detector import DeadlockDetector
from src.detectors.fs_exception_detector import FSExceptionDetector
import json
import hashlib
import socket

class ExceptionMonitor:
    def __init__(self, config_path=None):
        self.config = self.load_config(config_path)
        self.detectors = []
        self.results = []
        self.start_time = time.time()
        self.setup_detectors()
        print(f"âœ… å·²å¯ç”¨ {len(self.detectors)} ä¸ªæ£€æµ‹å™¨")
    
    def load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæä¾›æ›´å¥å£®çš„é»˜è®¤é…ç½®"""
        # é»˜è®¤é…ç½®ï¼ŒåŒ…å«æ‰€æœ‰æ£€æµ‹å™¨çš„å…³é”®è¯
        default_config = {
            'log_paths': [
                '/var/log',
                './test.log'
            ],
            'detectors': {
                'oom': {
                    'enabled': True,
                    'keywords': [
                        'Out of memory',
                        'oom-killer',
                        'Killed process',
                        'Memory cgroup out of memory'
                    ]
                },
                'panic': {
                    'enabled': True,
                    'keywords': [
                        'Kernel panic',
                        'kernel panic',
                        'not syncing',
                        'System halted'
                    ]
                },
                'reboot': {
                    'enabled': True,
                    'keywords': [
                        'unexpectedly shut down',
                        'unexpected restart',
                        'system reboot'
                    ]
                },
                # === æ–°å¢æ£€æµ‹å™¨é…ç½® ===
                'oops': {
                    'enabled': True,
                    'keywords': [
                        'Oops:',
                        'general protection fault',
                        'kernel BUG at',
                        'Unable to handle kernel',
                        'WARNING: CPU:',
                        'BUG: unable to handle kernel',
                        'invalid opcode:',
                        'stack segment:'
                    ]
                },
                'deadlock': {
                    'enabled': True,
                    'keywords': [
                        'possible deadlock',
                        'lock held',
                        'blocked for',
                        'stalled for',
                        'hung task',
                        'task blocked',
                        'soft lockup',
                        'hard lockup'
                    ]
                },
                'fs_exception': {
                    'enabled': True,
                    'keywords': [
                        'filesystem error',
                        'EXT4-fs error',
                        'XFS error',
                        'I/O error',
                        'file system corruption',
                        'superblock corrupt',
                        'metadata corruption',
                        'fsck needed'
                    ]
                }
                # === æ–°å¢æ£€æµ‹å™¨é…ç½®ç»“æŸ ===
            }
        }

        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if not config_path or not os.path.exists(config_path):
            print(f"âš ï¸  è­¦å‘Š: é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return default_config

        try:
            # åŠ è½½ç”¨æˆ·é…ç½®æ–‡ä»¶
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f) or {}
            
            # æ·±åº¦åˆå¹¶é…ç½®ï¼ˆé»˜è®¤é…ç½® + ç”¨æˆ·é…ç½®ï¼‰
            config = default_config.copy()
            for key in user_config:
                if key in config and isinstance(config[key], dict):
                    config[key].update(user_config[key])
                else:
                    config[key] = user_config[key]
            
            return config
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_path}: {e}")
            return default_config
    
    def setup_detectors(self):
        """åˆå§‹åŒ–æ£€æµ‹å™¨ï¼Œå¢åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯å’Œå¼‚å¸¸å¤„ç†"""
        detector_configs = self.config.get('detectors', {})
        
        # æ£€æµ‹å™¨æ˜ å°„è¡¨ï¼Œä¾¿äºåŠ¨æ€åŠ è½½
        detector_classes = {
            'oom': OOMDetector,
            'panic': PanicDetector,
            'reboot': RebootDetector,
            'oops': OopsDetector,
            'deadlock': DeadlockDetector,
            'fs_exception': FSExceptionDetector
        }
        
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ£€æµ‹å™¨...")
        
        # éå†æ‰€æœ‰æ£€æµ‹å™¨ç±»å‹ï¼ŒåŠ¨æ€åˆ›å»ºå®ä¾‹
        for detector_name, detector_class in detector_classes.items():
            config = detector_configs.get(detector_name, {})
            if config.get('enabled', False):
                try:
                    detector = detector_class(config)
                    self.detectors.append(detector)
                    keyword_count = len(config.get('keywords', []))
                    print(f"   âœ… {detector_name.upper()}æ£€æµ‹å™¨å·²åŠ è½½ ({keyword_count}ä¸ªå…³é”®è¯)")
                except Exception as e:
                    print(f"   âŒ {detector_name.upper()}æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
            else:
                print(f"   âš ï¸  {detector_name.upper()}æ£€æµ‹å™¨å·²ç¦ç”¨")
    
    def scan_logs(self):
        """æ‰«ææ—¥å¿—æ–‡ä»¶ï¼Œå¢åŠ è¯¦ç»†è¾“å‡ºå’Œè¿›åº¦ä¿¡æ¯"""
        print("\nğŸ” å¼€å§‹æ‰«æç³»ç»Ÿæ—¥å¿—...")
        total_files = 0
        total_detections = 0

        # æ”¶é›†æ‰€æœ‰å€™é€‰æ—¥å¿—æ–‡ä»¶
        candidate_files = self.collect_log_files()
        
        # é€ä¸ªæ‰«ææ—¥å¿—æ–‡ä»¶
        for abs_path in candidate_files:
            print(f"ğŸ“– æ­£åœ¨è¯»å–: {abs_path}")
            detections = self.check_log_file(abs_path)
            total_detections += len(detections)
            total_files += 1

        # å¦‚æœæ”¯æŒï¼Œæ‰«æ systemd journal
        if self.should_read_journal():
            print("ğŸ“– æ­£åœ¨è¯»å–: systemd journalctl")
            total_detections += self.scan_journal()
        
        # è¾“å‡ºæ‰«æç»Ÿè®¡
        elapsed_time = time.time() - self.start_time
        print(f"\nğŸ“Š æ‰«æå®Œæˆ!")
        print(f"   æ‰«ææ–‡ä»¶æ•°: {total_files}")
        print(f"   æ€»æ£€æµ‹æ¬¡æ•°: {total_detections}")
        print(f"   è€—æ—¶: {elapsed_time:.2f}ç§’")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        if total_detections > 0:
            self.show_statistics()
        else:
            print("\nâ„¹ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸äº‹ä»¶")
            print("å¯èƒ½åŸå› :")
            print("1. æ—¥å¿—æ–‡ä»¶ä¸­ç¡®å®æ²¡æœ‰åŒ¹é…çš„å¼‚å¸¸")
            print("2. æ£€æµ‹å…³é”®è¯éœ€è¦è°ƒæ•´")
            print("3. éœ€è¦æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æƒé™")
    
    def check_log_file(self, log_path):
        """æ£€æŸ¥å•ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œå¢åŠ è¡Œæ•°ç»Ÿè®¡å’Œå¼‚å¸¸å¤„ç†"""
        detections = []
        line_count = 0
        
        try:
            # å¤„ç†å‹ç¼©æ—¥å¿—æ–‡ä»¶
            if log_path.endswith('.gz'):
                f = gzip.open(log_path, 'rt', errors='ignore')
            else:
                f = open(log_path, 'r', errors='ignore')
                
            with f as fobj:
                for line in fobj:
                    line_count += 1
                    result = self.analyze_line(line)
                    if result:
                        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
                        result.update({
                            'file': log_path,
                            'line_number': line_count
                        })
                        detections.append(result)
            
            print(f"   å…±æ‰«æ {line_count} è¡Œæ—¥å¿—ï¼Œæ£€æµ‹åˆ° {len(detections)} ä¸ªå¼‚å¸¸")
            return detections
            
        except PermissionError:
            print(f"âŒ æƒé™ä¸è¶³ï¼Œæ— æ³•è¯»å–: {log_path}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨ sudo è¿è¡Œ:")
            print(f"   sudo python3 {__file__}")
            return []
        except Exception as e:
            print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶ {log_path} å‡ºé”™: {e}")
            return []

    def collect_log_files(self):
        """æ”¶é›†æ‰€æœ‰éœ€è¦æ‰«æçš„æ—¥å¿—æ–‡ä»¶"""
        files = []
        print("ğŸ“ æ­£åœ¨æ”¶é›†æ—¥å¿—æ–‡ä»¶...")
        
        base_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(base_dir)
        for p in self.config.get('log_paths', []):
            abs_path = os.path.abspath(p)
            if p.startswith('./') or p.startswith('../'):
                c1 = os.path.abspath(os.path.join(base_dir, p))
                c2 = os.path.abspath(os.path.join(parent_dir, p))
                abs_path = c1 if os.path.exists(c1) else c2
            if os.path.isfile(abs_path):
                files.append(abs_path)
                print(f"   ğŸ“„ æ·»åŠ æ–‡ä»¶: {abs_path}")
            elif os.path.isdir(abs_path):
                for root, dirs, filenames in os.walk(abs_path):
                    # è·³è¿‡ journal ç›®å½•
                    parts = root.replace('\\', '/').split('/')
                    if 'journal' in parts:
                        continue
                    for name in filenames:
                        if self.is_excluded_binary(name):
                            continue
                        if self.is_log_like(name):
                            full_path = os.path.join(root, name)
                            files.append(full_path)
                            print(f"   ğŸ“„ æ·»åŠ æ—¥å¿—æ–‡ä»¶: {full_path}")
        
        print(f"   ğŸ“ æ€»å…±æ‰¾åˆ° {len(files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        return files

    def is_log_like(self, name):
        """åˆ¤æ–­æ–‡ä»¶åæ˜¯å¦åƒæ—¥å¿—æ–‡ä»¶"""
        lower = name.lower()
        if lower.endswith('.log'):
            return True
        if '.log.' in lower:
            return True
        bases = {
            'syslog', 'messages', 'kern.log', 'dmesg', 'auth.log', 'daemon.log',
            'boot.log', 'cron', 'xorg.log', 'yum.log', 'pacman.log', 'dpkg.log',
            'audit.log'
        }
        return any(lower.startswith(b) for b in bases) or lower.endswith('.gz')

    def is_excluded_binary(self, name):
        """æ’é™¤äºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶"""
        lower = name.lower()
        excluded = {'lastlog', 'wtmp', 'btmp', 'faillog', 'utmp'}
        for ex in excluded:
            if lower.startswith(ex):
                return True
        return False

    def should_read_journal(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¯»å– systemd journal"""
        if platform.system() != 'Linux':
            return False
        if not shutil.which('journalctl'):
            return False
        return True

    def scan_journal(self):
        """æ‰«æ systemd journal"""
        detections = 0
        try:
            # ä½¿ç”¨ subprocess è°ƒç”¨ journalctl
            p = subprocess.Popen(
                ['journalctl', '-o', 'short-iso', '--no-pager'],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                errors='ignore'
            )
            
            # é€è¡Œå¤„ç† journal è¾“å‡º
            for line in p.stdout:
                result = self.analyze_line(line)
                if result:
                    result.update({'file': 'journalctl', 'line_number': 0})
                    self.results.append(result)
                    detections += 1
                    
            p.wait()
            print(f"   ä» journalctl æ£€æµ‹åˆ° {detections} ä¸ªå¼‚å¸¸")
            return detections
            
        except Exception as e:
            print(f"âŒ è¯»å–journalctlå¤±è´¥: {e}")
            return 0
    
    def analyze_line(self, line):
        """åˆ†æå•è¡Œæ—¥å¿—ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†ç¡®ä¿å•ä¸ªæ£€æµ‹å™¨é”™è¯¯ä¸å½±å“æ•´ä½“"""
        for detector in self.detectors:
            try:
                result = detector.detect(line)
                if result:
                    self.handle_detection(result)
                    return result
            except Exception as e:
                # å•ä¸ªæ£€æµ‹å™¨å‡ºé”™ä¸å½±å“å…¶ä»–æ£€æµ‹å™¨
                print(f"âŒ æ£€æµ‹å™¨ {detector.name} å¤„ç†è¡Œæ—¶å‡ºé”™: {e}")
                print(f"   é—®é¢˜è¡Œ: {line[:100]}...")
                continue  # ç»§ç»­æ‰§è¡Œå…¶ä»–æ£€æµ‹å™¨
        return None
    
    def handle_detection(self, result):
        """å¤„ç†æ£€æµ‹ç»“æœï¼Œä¼˜åŒ–è¾“å‡ºæ ¼å¼"""
        self.results.append(result)
        
        # æ ¹æ®ä¸¥é‡çº§åˆ«é€‰æ‹©è¡¨æƒ…ç¬¦å·
        severity_emoji = {
            'critical': 'ğŸ”¥',
            'high': 'ğŸš¨',
            'medium': 'âš ï¸',
            'low': 'â„¹ï¸'
        }.get(result.get('severity', 'medium'), 'ğŸ“')
        
        # æˆªæ–­è¿‡é•¿çš„æ¶ˆæ¯
        message_preview = result['message'][:100] + '...' if len(result['message']) > 100 else result['message']
        print(f"{severity_emoji} [{result['type'].upper()}] {message_preview}")
        try:
            self.persist_event(result)
        except Exception as e:
            print(f"âŒ æ•°æ®å†™å…¥å¤±è´¥: {e}")

    def persist_event(self, result):
        data_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '..', 'data'))
        os.makedirs(data_dir, exist_ok=True)
        anomalies = os.path.join(data_dir, 'anomalies.ndjson')
        summary_file = os.path.join(data_dir, 'summary.json')

        detected_at = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')
        source_file = result.get('file', '')
        line_number = result.get('line_number', 0)
        host_id = socket.gethostname()
        msg = result.get('message', '')
        raw_id = f"{host_id}{source_file}{line_number}{detected_at}{msg}".encode('utf-8')
        eid = hashlib.sha256(raw_id).hexdigest()[:16]
        sev_map = {"critical": "critical", "high": "major", "medium": "minor", "low": "minor"}
        sev = sev_map.get(result.get('severity', 'medium'), 'minor')
        event = {
            "schema_version": "1.0",
            "id": eid,
            "type": result.get('type'),
            "severity": sev,
            "message": msg,
            "source_file": source_file,
            "line_number": line_number,
            "detected_at": detected_at,
            "host_id": host_id,
            "processed": False
        }
        with open(anomalies, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event) + "\n")
        day_dir = os.path.join(data_dir, 'anomalies')
        os.makedirs(day_dir, exist_ok=True)
        day_file = os.path.join(day_dir, datetime.utcnow().strftime('%Y-%m-%d') + '.ndjson')
        with open(day_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event) + "\n")
        if os.path.exists(summary_file):
            with open(summary_file, 'r', encoding='utf-8') as f:
                s = json.load(f)
        else:
            s = {
                "schema_version": "1.0",
                "date": datetime.utcnow().strftime('%Y-%m-%d'),
                "total_anomalies": 0,
                "by_severity": {"critical": 0, "major": 0, "minor": 0},
                "by_type": {},
                "hosts": [],
                "trend": []
            }
        s['total_anomalies'] = int(s.get('total_anomalies', 0)) + 1
        bs = s.get('by_severity', {"critical": 0, "major": 0, "minor": 0})
        bs[sev] = int(bs.get(sev, 0)) + 1
        s['by_severity'] = bs
        bt = s.get('by_type', {})
        t = event['type']
        bt[t] = int(bt.get(t, 0)) + 1
        s['by_type'] = bt
        s['last_detection'] = detected_at
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(s, f)
    
    def show_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œç¡®ä¿æ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹å™¨ç±»å‹ï¼ˆåŒ…æ‹¬è®¡æ•°ä¸º0çš„ï¼‰"""
        print("\nğŸ“ˆ æ£€æµ‹ç»Ÿè®¡:")
        print("-" * 50)
        
        # ç¡®ä¿æ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹å™¨ç±»å‹ï¼Œå³ä½¿è®¡æ•°ä¸º0
        stats = {}
        detector_types = [detector.name for detector in self.detectors]
        
        # ç»Ÿè®¡æ¯ä¸ªæ£€æµ‹å™¨çš„æ£€æµ‹æ•°é‡
        for detector_type in detector_types:
            count = len([r for r in self.results if r['type'] == detector_type])
            stats[detector_type] = count
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸
        if not any(stats.values()):
            print("   æœªæ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸äº‹ä»¶")
            return
        
        # æŒ‰æ£€æµ‹æ•°é‡é™åºæ’åˆ—æ˜¾ç¤º
        for name, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
            status = "âœ…" if count > 0 else "âŒ"
            print(f"   {status} {name.upper():<12}: {count} æ¬¡")
    
    def save_report(self, output_file):
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Šï¼Œå¢åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯"""
        if not self.results:
            print("âš ï¸  æ²¡æœ‰æ£€æµ‹åˆ°å¼‚å¸¸ï¼Œä¸ç”ŸæˆæŠ¥å‘Š")
            return

        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            directory = os.path.dirname(os.path.abspath(output_file))
            if directory and not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)

            # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("æ“ä½œç³»ç»Ÿå¼‚å¸¸æ£€æµ‹æŠ¥å‘Š\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ‰«ææ–‡ä»¶æ•°: {len(self.collect_log_files())}\n")
                f.write(f"æ£€æµ‹åˆ°å¼‚å¸¸: {len(self.results)} ä¸ª\n")
                f.write("=" * 60 + "\n\n")

                # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤ºç»“æœ
                results_by_type = {}
                for result in self.results:
                    result_type = result['type']
                    if result_type not in results_by_type:
                        results_by_type[result_type] = []
                    results_by_type[result_type].append(result)
                
                # æŒ‰ç±»å‹è¾“å‡ºç»“æœ
                for result_type, type_results in results_by_type.items():
                    f.write(f"\nã€{result_type.upper()} å¼‚å¸¸ã€‘å…± {len(type_results)} ä¸ª:\n")
                    f.write("-" * 50 + "\n")
                    
                    for i, result in enumerate(type_results, 1):
                        f.write(f"{i}. ä¸¥é‡æ€§: {result.get('severity', 'UNKNOWN').upper()}\n")
                        f.write(f"   æ—¶é—´: {result.get('formatted_time', 'æœªçŸ¥')}\n")
                        f.write(f"   æ¥æº: {result.get('file', 'æœªçŸ¥')}:{result.get('line_number', 'æœªçŸ¥')}\n")
                        f.write(f"   å†…å®¹: {result['message']}\n")
                        f.write("\n")

            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {os.path.abspath(output_file)}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¢åŠ å¸®åŠ©ä¿¡æ¯"""
    parser = argparse.ArgumentParser(
        description='æ“ä½œç³»ç»Ÿå¼‚å¸¸ä¿¡æ¯æ£€æµ‹å·¥å…·',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument('-c', '--config',
                       default='config/default.yaml',
                       help='æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„')
    
    parser.add_argument('-o', '--output',
                       default='report.txt',
                       help='æŒ‡å®šè¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    return parser.parse_args()

def main():
    """ä¸»ç¨‹åºå…¥å£ï¼Œå¢åŠ æ¬¢è¿ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ–¥ï¸  æ“ä½œç³»ç»Ÿå¼‚å¸¸ä¿¡æ¯æ£€æµ‹å·¥å…· v1.0")
    print("=" * 60)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # åˆ›å»ºç›‘æ§å®ä¾‹å¹¶æ‰§è¡Œæ‰«æ
    monitor = ExceptionMonitor(args.config)
    monitor.scan_logs()
    
    # ä¿å­˜æŠ¥å‘Š
    monitor.save_report(args.output)
    
    print("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")

if __name__ == "__main__":
    main()
